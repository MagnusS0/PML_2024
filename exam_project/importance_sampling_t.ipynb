{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling for t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main changes: **elbo_simple**, **weight_function**, **update_loss_squared_history**, **loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired on: Nichol, A.Q. and Dhariwal, P., 2021. Improved denoising diffusion probabilistic models. In\n",
    "International conference on machine learning, PMLR. https://arxiv.org/abs/2102.09672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This UNET-style prediction model was originally included as part of the Score-based generative modelling tutorial\n",
    "# by Yang Song et al: https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed\n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "\n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    # Obtain the Gaussian random feature embedding for t\n",
    "    embed = self.act(self.embed(t))\n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)\n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialMovingAverage(torch.optim.swa_utils.AveragedModel):\n",
    "    \"\"\"Maintains moving averages of model parameters using an exponential decay.\n",
    "    ``ema_avg = decay * avg_model_param + (1 - decay) * model_param``\n",
    "    `torch.optim.swa_utils.AveragedModel <https://pytorch.org/docs/stable/optim.html#custom-averaging-strategies>`_\n",
    "    is used to compute the EMA.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay, device=\"cpu\"):\n",
    "        def ema_avg(avg_model_param, model_param, num_averaged):\n",
    "            return decay * avg_model_param + (1 - decay) * model_param\n",
    "\n",
    "        super().__init__(model, device, ema_avg, use_buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "\n",
    "    def __init__(self, network, T=100, beta_1=1e-4, beta_T=2e-2):\n",
    "        \"\"\"\n",
    "        Initialize Denoising Diffusion Probabilistic Model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        network: nn.Module\n",
    "            The inner neural network used by the diffusion process. Typically a Unet.\n",
    "        beta_1: float\n",
    "            beta_t value at t=1\n",
    "        beta_T: [float]\n",
    "            beta_t value at t=T (last step)\n",
    "        T: int\n",
    "            The number of diffusion steps.\n",
    "        \"\"\"\n",
    "\n",
    "        super(DDPM, self).__init__()\n",
    "\n",
    "        # Normalize time input before evaluating neural network\n",
    "        # Reshape input into image format and normalize time value before sending it to network model\n",
    "        self._network = network\n",
    "        self.network = lambda x, t: (self._network(x.reshape(-1, 1, 28, 28),\n",
    "                                                   (t.squeeze()/T))\n",
    "                                    ).reshape(-1, 28*28)\n",
    "\n",
    "        # Total number of time steps\n",
    "        self.T = T\n",
    "\n",
    "        # Registering as buffers to ensure they get transferred to the GPU automatically\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_1, beta_T, T+1))\n",
    "        self.register_buffer(\"alpha\", 1-self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", self.alpha.cumprod(dim=0))\n",
    "\n",
    "        self.loss_squared_history = {t: [] for t in range(T)}\n",
    "    \n",
    "    def forward_diffusion(self, x0, t, epsilon):\n",
    "        '''\n",
    "        q(x_t | x_0)\n",
    "        Forward diffusion from an input datapoint x0 to an xt at timestep t, provided a N(0,1) noise sample epsilon.\n",
    "        Note that we can do this operation in a single step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0: torch.tensor\n",
    "            x value at t=0 (an input image)\n",
    "        t: int\n",
    "            step index\n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t\n",
    "        '''\n",
    "\n",
    "        mean = torch.sqrt(self.alpha_bar[t])*x0\n",
    "        std = torch.sqrt(1 - self.alpha_bar[t])\n",
    "\n",
    "        return mean + std*epsilon\n",
    "\n",
    "    def reverse_diffusion(self, xt, t, epsilon):\n",
    "        \"\"\"\n",
    "        p(x_{t-1} | x_t)\n",
    "        Single step in the reverse direction, from x_t (at timestep t) to x_{t-1}, provided a N(0,1) noise sample epsilon.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xt: torch.tensor\n",
    "            x value at step t\n",
    "        t: int\n",
    "            step index\n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t-1\n",
    "        \"\"\"\n",
    "\n",
    "        mean =  1./torch.sqrt(self.alpha[t]) * (xt - (self.beta[t])/torch.sqrt(1-self.alpha_bar[t])*self.network(xt, t))\n",
    "        std = torch.where(t>0, torch.sqrt(((1-self.alpha_bar[t-1]) / (1-self.alpha_bar[t]))*self.beta[t]), 0)\n",
    "\n",
    "        return mean + std*epsilon\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, shape):\n",
    "        \"\"\"\n",
    "        Sample from diffusion model (Algorithm 2 in Ho et al, 2020)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape: tuple\n",
    "            Specify shape of sampled output. For MNIST: (nsamples, 28*28)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            sampled image\n",
    "        \"\"\"\n",
    "\n",
    "        # Sample xT: Gaussian noise\n",
    "        xT = torch.randn(shape).to(self.beta.device)\n",
    "\n",
    "        xt = xT\n",
    "        for t in range(self.T, 0, -1):\n",
    "            noise = torch.randn_like(xT) if t > 1 else 0\n",
    "            t = torch.tensor(t).expand(xt.shape[0], 1).to(self.beta.device)\n",
    "            xt = self.reverse_diffusion(xt, t, noise)\n",
    "\n",
    "        return xt\n",
    "\n",
    "    def elbo_simple(self, x0, weight_function=None):\n",
    "        \"\"\"\n",
    "        ELBO training objective with importance sampling.\n",
    "        \"\"\"\n",
    "        # Sample time step t\n",
    "        t = torch.randint(1, self.T, (x0.shape[0], 1)).to(x0.device)\n",
    "        # Importance weight for each t\n",
    "        if weight_function is not None:\n",
    "            weights = weight_function(t.float())\n",
    "            weights = weights / weights.sum()  # Normalize weights\n",
    "        else:\n",
    "            weights = torch.ones_like(t, dtype=torch.float32, device=x0.device)\n",
    "        # Sample noise\n",
    "        epsilon = torch.randn_like(x0)\n",
    "        # Forward diffusion to produce image at step t\n",
    "        xt = self.forward_diffusion(x0, t, epsilon)\n",
    "        # Compute loss for predicting noise\n",
    "        loss = nn.MSELoss(reduction='none')(epsilon, self.network(xt, t))\n",
    "        # Update history of L_t^2\n",
    "        self.update_loss_squared_history(t, loss)\n",
    "        # Apply importance weights\n",
    "        loss = (loss.mean(dim=1) * weights.squeeze()).mean()\n",
    "        return -loss\n",
    "\n",
    "    def weight_function(self, t):\n",
    "        \"\"\"\n",
    "        Importance sampling weight function based on E[L_t^2] using a history.\n",
    "        \"\"\"\n",
    "        t = t.squeeze().long()\n",
    "        weights = []\n",
    "        for timestep in t:\n",
    "            history = self.loss_squared_history[timestep.item()]\n",
    "            if len(history) > 0:\n",
    "                # Compute E[L_t^2] as the mean of the last 10 values\n",
    "                weights.append(torch.sqrt(torch.mean(torch.tensor(history))))\n",
    "            else:\n",
    "                # Default weight if no history is available\n",
    "                weights.append(torch.tensor(1.0))\n",
    "        return torch.tensor(weights, device=t.device)\n",
    "\n",
    "    def update_loss_squared_history(self, t, loss):\n",
    "        \"\"\"\n",
    "        Update the history of L_t^2 for each timestep.\n",
    "        \"\"\"\n",
    "        t = t.squeeze().long()\n",
    "        # Calculate L_t^2 for the given timesteps\n",
    "        loss_squared = loss.mean(dim=1) ** 2  # Mean over batch dimension\n",
    "        for i in range(t.shape[0]):\n",
    "            timestep = t[i].item()\n",
    "            if timestep in self.loss_squared_history:\n",
    "                # Update the history with a new value\n",
    "                self.loss_squared_history[timestep].append(loss_squared[i].item())\n",
    "                # Keep only the last 10 values\n",
    "                if len(self.loss_squared_history[timestep]) > 10:\n",
    "                    self.loss_squared_history[timestep].pop(0)\n",
    "\n",
    "    def loss(self, x0):\n",
    "        \"\"\"\n",
    "        Loss function. Just the negative of the ELBO.\n",
    "        \"\"\"\n",
    "        return -self.elbo_simple(x0, weight_function=self.weight_function).mean()\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, dataloader, epochs, device, ema=True, per_epoch_callback=None):\n",
    "    \"\"\"\n",
    "    Training loop\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        Pytorch model\n",
    "    optimizer: optim.Optimizer\n",
    "        Pytorch optimizer to be used for training\n",
    "    scheduler: optim.LRScheduler\n",
    "        Pytorch learning rate scheduler\n",
    "    dataloader: utils.DataLoader\n",
    "        Pytorch dataloader\n",
    "    epochs: int\n",
    "        Number of epochs to train\n",
    "    device: torch.device\n",
    "        Pytorch device specification\n",
    "    ema: Boolean\n",
    "        Whether to activate Exponential Model Averaging\n",
    "    per_epoch_callback: function\n",
    "        Called at the end of every epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup progress bar\n",
    "    total_steps = len(dataloader)*epochs\n",
    "    progress_bar = tqdm(range(total_steps), desc=\"Training\")\n",
    "\n",
    "    if ema:\n",
    "        ema_global_step_counter = 0\n",
    "        ema_steps = 10\n",
    "        ema_adjust = dataloader.batch_size * ema_steps / epochs\n",
    "        ema_decay = 1.0 - 0.995\n",
    "        ema_alpha = min(1.0, (1.0 - ema_decay) * ema_adjust)\n",
    "        ema_model = ExponentialMovingAverage(model, device=device, decay=1.0 - ema_alpha)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        global_step_counter = 0\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=f\"â €{loss.item():12.4f}\", epoch=f\"{epoch+1}/{epochs}\", lr=f\"{scheduler.get_last_lr()[0]:.2E}\")\n",
    "            progress_bar.update()\n",
    "\n",
    "            if ema:\n",
    "                ema_global_step_counter += 1\n",
    "                if ema_global_step_counter%ema_steps==0:\n",
    "                    ema_model.update_parameters(model)\n",
    "\n",
    "        if per_epoch_callback:\n",
    "            per_epoch_callback(ema_model.module if ema else model)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "T = 1000\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Rather than treating MNIST images as discrete objects, as done in Ho et al 2020,\n",
    "# we here treat them as continuous input data, by dequantizing the pixel values (adding noise to the input data)\n",
    "# Also note that we map the 0..255 pixel values to [-1, 1], and that we process the 28x28 pixel values as a flattened 784 tensor.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x-0.5)*2.0),                    # Map from [0,1] -> [-1, -1]\n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Download and transform train dataset\n",
    "dataloader_train = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Construct Unet\n",
    "# The original ScoreNet expects a function with std for all the\n",
    "# different noise levels, such that the output can be rescaled.\n",
    "# Since we are predicting the noise (rather than the score), we\n",
    "# ignore this rescaling and just set std=1 for all t.\n",
    "mnist_unet = ScoreNet((lambda t: torch.ones(1).to(device)))\n",
    "\n",
    "# Construct model\n",
    "model = DDPM(mnist_unet, T=T).to(device)\n",
    "\n",
    "# Construct optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Setup simple scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9999)\n",
    "\n",
    "\n",
    "def reporter(model):\n",
    "    \"\"\"Callback function used for plotting images during training\"\"\"\n",
    "\n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nsamples = 10\n",
    "        samples = model.sample((nsamples,28*28)).cpu()\n",
    "\n",
    "        # Map pixel values back from [-1,1] to [0,1]\n",
    "        samples = (samples+1)/2\n",
    "        samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "        # Plot in grid\n",
    "        grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "        plt.gca().set_axis_off()\n",
    "        plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "#Call training loop\n",
    "train(model, optimizer, scheduler, dataloader_train,\n",
    "      epochs=epochs, device=device, ema=True, per_epoch_callback=reporter)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
